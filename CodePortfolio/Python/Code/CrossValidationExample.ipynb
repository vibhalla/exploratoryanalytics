{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "#Dataset with two skin segments (1, 2 based on Red/Green/Blue value features) \n",
    "#from: https://archive.ics.uci.edu/ml/datasets/Skin+Segmentation\n",
    "skin_segmentation = pd.read_csv(\"SkinSegmentation.txt\", sep=\"\\t\")\n",
    "#Randomizing dataset so that we don't have deterministic results (i.e. results can vary from run to run)\n",
    "skin_segmentation = skin_segmentation.sample(frac=1)\n",
    "#Adding column-names to dataset for readability and usability\n",
    "skin_segmentation.columns = [\"R\",\"G\",\"B\",\"Class\"]\n",
    "\n",
    "#k-fold cross validation\n",
    "k=10\n",
    "\n",
    "chunk_size = math.floor(skin_segmentation.shape[0]/k)\n",
    "accuracy_accumulation = []\n",
    "\n",
    "for iteration in range(1, k+1):\n",
    "    print(\"Computing fold where test chunk is:\", k-iteration)\n",
    "    \n",
    "    #Ascribing the test_set and training_set depending on the fold\n",
    "    test_set = skin_segmentation.iloc[(k-iteration)*chunk_size:(k-iteration+1)*chunk_size, ]\n",
    "    training_set_left = skin_segmentation.iloc[:(k-iteration)*chunk_size, ]\n",
    "    training_set_right = skin_segmentation.iloc[(k-iteration+1)*chunk_size:, ]\n",
    "    training_set = training_set_left.append(training_set_right)\n",
    "    \n",
    "    #We train on the training-data here, very simple training classifier/model where we just tally up how many \n",
    "    #of a certain class we see and compute the probability of the given class for the whole training data\n",
    "    print(\"Training...\")\n",
    "    ones = sum((training_set[[\"Class\"]] == 1).values.T.tolist()[0])\n",
    "    twos = sum((training_set[[\"Class\"]] == 2).values.T.tolist()[0])\n",
    "\n",
    "    total = ones + twos\n",
    "    ones_prob = ones/total\n",
    "    twos_prob = twos/total\n",
    "    \n",
    "    print(\"Finished Training, now Testing...\")\n",
    "    # We trained out simple model, now we test on our test data and see how well we do\n",
    "    true_values = test_set[[\"Class\"]]\n",
    "    predicted_values = []\n",
    "    for sample in test_set.iterrows():\n",
    "        #Random number between 0 and 1\n",
    "        class_generation = random.random()\n",
    "        #Here we pick the class that has the closest probability (from training) based on the random draw\n",
    "        choose_one = abs(class_generation - ones_prob)\n",
    "        choose_two = abs(class_generation - twos_prob)\n",
    "        if choose_one < choose_two:\n",
    "            predicted_values.append(1)\n",
    "        else:\n",
    "            predicted_values.append(2)\n",
    "\n",
    "    comparison_list = (true_values == predicted_values).values.T.tolist()\n",
    "    accuracy = sum(comparison_list[0])/len(predicted_values)\n",
    "    print(\"Fold Accuracy:\", accuracy*100, \"%\")\n",
    "    accuracy_accumulation.append(accuracy)\n",
    "    \n",
    "#Printing accuracy for each iteration\n",
    "print(accuracy_accumulation)\n",
    "#Printing averaged accuracy\n",
    "print(\"Averaged Accuracy:\", (sum(accuracy_accumulation)/len(accuracy_accumulation))*100, \"%\")\n",
    "#Printing averaged error\n",
    "print(\"Averaged Error:\", (1-sum(accuracy_accumulation)/len(accuracy_accumulation))*100, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
